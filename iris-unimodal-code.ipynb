{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, random\nimport numpy as np\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, confusion_matrix, roc_curve, auc\n)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nIRIS_DIR = \"/kaggle/input/multimodal-biometric-dataset-mulb/MULB dataset/iris dataset\"\n\nBATCH_SIZE = 16\nEPOCHS = 30\nLR = 1e-4\n\nEMBED_DIM = 256          \nMARGIN = 1.0             # Triplet margin\nFREEZE_EPOCHS = 5        # Freeze backbone initially\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", DEVICE)\n\n\ndef collect_images(subject_dir):\n    return [\n        os.path.join(root, f)\n        for root, _, files in os.walk(subject_dir)\n        for f in files if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))\n    ]\n\ndef build_subject_dict(base_dir):\n    data = {}\n    for s in sorted(os.listdir(base_dir)):\n        p = os.path.join(base_dir, s)\n        if os.path.isdir(p):\n            imgs = collect_images(p)\n            if len(imgs) >= 3:\n                data[s] = imgs\n    return data\n\n# Dataset Preparation\n\niris_dict = build_subject_dict(IRIS_DIR)\nsubjects = list(iris_dict.keys())\nrandom.shuffle(subjects)\n\nsplit = int(0.8 * len(subjects))\ntrain_subjects = subjects[:split]\nval_subjects = subjects[split:]\n\nprint(\"Total subjects:\", len(subjects))\n\n# Data Augmentation\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.75, 1.0)),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(0.2, 0.2, 0.2, 0.05),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\n# Dataset\n\nclass IrisTripletDataset(Dataset):\n    def __init__(self, subjects, iris_dict, transform):\n        self.subjects = subjects\n        self.iris_dict = iris_dict\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.subjects) * 5\n\n    def __getitem__(self, idx):\n        anchor_subject = random.choice(self.subjects)\n        negative_subject = random.choice(\n            [s for s in self.subjects if s != anchor_subject]\n        )\n\n        anchor, positive = random.sample(self.iris_dict[anchor_subject], 2)\n        negative = random.choice(self.iris_dict[negative_subject])\n\n        return (\n            self.transform(Image.open(anchor).convert(\"RGB\")),\n            self.transform(Image.open(positive).convert(\"RGB\")),\n            self.transform(Image.open(negative).convert(\"RGB\"))\n        )\n\ntrain_loader = DataLoader(\n    IrisTripletDataset(train_subjects, iris_dict, train_transform),\n    batch_size=BATCH_SIZE, shuffle=True\n)\n\nval_loader = DataLoader(\n    IrisTripletDataset(val_subjects, iris_dict, val_transform),\n    batch_size=BATCH_SIZE, shuffle=False\n)\n\n# Model Code\n\ndef get_backbone():\n    model = models.efficientnet_b0(\n        weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1\n    )\n    model.classifier = nn.Identity()\n    return model\n\nclass ProjectionHead(nn.Module):\n    def __init__(self, in_dim=1280, out_dim=EMBED_DIM):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Linear(512, out_dim),\n            nn.BatchNorm1d(out_dim)\n        )\n\n    def forward(self, x):\n        return F.normalize(self.net(x), dim=1)\n\nclass IrisEmbeddingNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = get_backbone()\n        self.proj = ProjectionHead()\n\n    def forward(self, x):\n        f = self.encoder(x)\n        if f.ndim == 4:\n            f = F.adaptive_avg_pool2d(f, 1).flatten(1)\n        return self.proj(f)\n\n# Triplet Loss\n\nclass TripletLoss(nn.Module):\n    def __init__(self, margin=MARGIN):\n        super().__init__()\n        self.margin = margin\n\n    def forward(self, anchor, positive, negative):\n        d_pos = F.pairwise_distance(anchor, positive)\n        d_neg = F.pairwise_distance(anchor, negative)\n        return torch.mean(F.relu(d_pos - d_neg + self.margin))\n\n# Training Function\n\nmodel = IrisEmbeddingNet().to(DEVICE)\ncriterion = TripletLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n\n# Freeze backbone initially\nfor p in model.encoder.parameters():\n    p.requires_grad = False\n\nfor epoch in range(EPOCHS):\n\n    if epoch == FREEZE_EPOCHS:\n        print(\"Unfreezing backbone...\")\n        for p in model.encoder.parameters():\n            p.requires_grad = True\n\n    model.train()\n    epoch_loss = 0\n\n    for a, p, n in train_loader:\n        a, p, n = a.to(DEVICE), p.to(DEVICE), n.to(DEVICE)\n\n        optimizer.zero_grad()\n        za = model(a)\n        zp = model(p)\n        zn = model(n)\n\n        loss = criterion(za, zp, zn)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    epoch_loss /= len(train_loader)\n    print(f\"Epoch [{epoch+1}/{EPOCHS}] Train Loss: {epoch_loss:.4f}\")\n\n\n# Evaluation (FAR, FRR, EER)\n\nmodel.eval()\ndists, labels = [], []\n\nwith torch.no_grad():\n    for a, p, n in val_loader:\n        a, p, n = a.to(DEVICE), p.to(DEVICE), n.to(DEVICE)\n\n        za = model(a)\n        zp = model(p)\n        zn = model(n)\n\n        # Genuine pairs\n        dists.extend(F.pairwise_distance(za, zp).cpu().numpy())\n        labels.extend([1] * za.size(0))\n\n        # Impostor pairs\n        dists.extend(F.pairwise_distance(za, zn).cpu().numpy())\n        labels.extend([0] * za.size(0))\n\ndists = np.array(dists)\nlabels = np.array(labels)\n\n# ROC & EER\nfpr, tpr, thresholds = roc_curve(labels, -dists)\nfar = fpr\nfrr = 1 - tpr\n\neer_idx = np.nanargmin(np.abs(far - frr))\neer = far[eer_idx]\neer_threshold = -thresholds[eer_idx]\n\ny_pred = (dists < eer_threshold).astype(int)\n\n# Metrics\n\nacc = accuracy_score(labels, y_pred)\nprec = precision_score(labels, y_pred)\nrec = recall_score(labels, y_pred)\nf1 = f1_score(labels, y_pred)\nroc_auc = auc(fpr, tpr)\n\nprint(\"\\n===== MULTIMODAL HAND + IRIS RESULTS =====\")\nprint(f\"Accuracy  : {acc:.4f}\")\nprint(f\"Precision : {prec:.4f}\")\nprint(f\"Recall    : {rec:.4f}\")\nprint(f\"F1-score  : {f1:.4f}\")\nprint(f\"ROC-AUC   : {roc_auc:.4f}\")\n\nprint(\"\\n===== BIOMETRIC ERROR RATES =====\")\nprint(f\"FAR : {far[eer_idx]:.4f}\")\nprint(f\"FRR : {frr[eer_idx]:.4f}\")\nprint(f\"EER : {eer:.4f}\")\n\ntorch.save(model.state_dict(), \"iris_triplet_efficientnet.pth\")\nprint(\"Model saved successfully.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}